# interview




## 1. 요즘 Sigmoid보다 ReLU를 많이 쓰는데 그 이유는?
### +
### +
### +
### +

## 2. Gradient Descent에 대해서 쉽게 설명한다면?
### +
### +
### +
### +
### +
### +

## 3. Local Minima문제에도 불구하고 딥러닝이 잘 되는 이유는?
### +
### +

## 4. CNN에 대해서 아는대로 얘기해라
### +
### +
### +
### +
### +

## 5. Word2Vec의 원리는?
### +
### +
### +
### +

## 6. Auto Encoder에 대해서 아는대로 얘기해라
### +
### +
### +
### +
### +

## 7. Training세트와 Test세트를 분리하는 이유는?
### +
### +
### +

## 8. Batch Normalization의 효과는?
### +
### +
### +
## 9. SGD, RMSprop, Adam에 대해서 아는대로 설명한다면?
### +
### +
### +

## 10. 간단한 MNIST 분류기를 MLP+CPU 버전으로 numpy로 만든다면 몇줄일까?
### +
### +
### +

## 11. 간단한 MNIST 분류기를 TF나 Keras등으로 작성하는데 몇시간이 필요한가?
### +
### +
### +
### +

## 12. 간단한 MNIST DCGAN을 작성한다면 TF등으로 몇줄 정도 될까?
### +
### +
### +

## 13. 딥러닝할 때 GPU를 쓰면 좋은 이유는?
### +
### +
### +

## 14. TF 또는 Keras등을 사용할 때 디버깅 노하우는?

## 15. Collaborative Filtering에 대해 설명한다면?

## 16. AutoML이 뭐하는 걸까?
